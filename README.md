# DAMP: Diffusion-based Antimicrobial Peptide Generator

A deep learning system for generating novel antimicrobial peptides using diffusion models and graph neural networks.

## ğŸš€ Quick Start

### Installation
```bash
# Clone the repository
git clone <repository-url>
cd DAMP

# Install dependencies using uv
uv sync

# Activate virtual environment
source .venv/bin/activate  # On Unix/macOS
# or
.venv\Scripts\activate     # On Windows
```

### Basic Usage
```bash
# Run the main application
python run.py --epochs 50 --num_sequences 100

# Demo mode (quick training)
python run.py --demo

# Use existing models
python run.py --skip_training --num_sequences 50
```

## ğŸ“ Project Structure

```
DAMP/
â”œâ”€â”€ run.py                          # Main entry point
â”œâ”€â”€ src/                            # Core source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data.py                     # Data loading and processing
â”‚   â”œâ”€â”€ models.py                   # Neural network models
â”‚   â”œâ”€â”€ trainer.py                  # Training utilities
â”‚   â”œâ”€â”€ generator.py                # Sequence generation
â”‚   â””â”€â”€ evaluator.py                # Quality evaluation
â”œâ”€â”€ scripts/                        # Main scripts
â”‚   â”œâ”€â”€ main.py                     # Main training script
â”‚   â””â”€â”€ demo.py                     # Demo script
â”œâ”€â”€ test/                           # Test files
â”‚   â”œâ”€â”€ test_enhanced_training.py   # Enhanced training tests
â”‚   â”œâ”€â”€ test_generation.py          # Generation tests
â”‚   â”œâ”€â”€ test_model_comparison.py    # Model comparison tests
â”‚   â”œâ”€â”€ test_data_loading.py        # Data loading tests
â”‚   â””â”€â”€ test_improved.py            # Legacy test file
â”œâ”€â”€ visualization/                  # Visualization tools
â”‚   â”œâ”€â”€ plot_training_curves.py     # Training curve plots
â”‚   â”œâ”€â”€ advanced_plotting.py        # Advanced visualizations
â”‚   â””â”€â”€ training_visualization_summary.md
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md
â”‚   â””â”€â”€ roadmap.md
â”œâ”€â”€ dataset/                        # Data files
â”‚   â”œâ”€â”€ naturalAMPs_APD2024a.fasta  # AMP sequences
â”‚   â””â”€â”€ non-amp.fasta              # Non-AMP sequences
â”œâ”€â”€ models/                         # Trained models
â”œâ”€â”€ results/                        # Generation results
â”œâ”€â”€ plots/                          # Generated plots
â”œâ”€â”€ logs/                           # Training logs
â”œâ”€â”€ config.py                       # Configuration
â”œâ”€â”€ requirements.txt                # Dependencies
â””â”€â”€ pyproject.toml                  # Project metadata
```

## ğŸ§ª Testing

### Run Tests
```bash
# Run all tests
python test/test_enhanced_training.py
python test/test_generation.py
python test/test_model_comparison.py
python test/test_data_loading.py
```

### Data Loading Test
```bash
python test/test_data_loading.py
```

### Model Comparison
```bash
python test/test_model_comparison.py
```

## ğŸ“Š Visualization

### Generate Training Plots
```bash
# Basic training curves
python visualization/plot_training_curves.py

# Advanced visualizations
python visualization/advanced_plotting.py
```

### Available Visualizations
- Training loss curves
- Model comparison heatmaps
- Performance radar charts
- Training analysis dashboard
- Improvement analysis plots

## ğŸ”§ Configuration

### Model Configuration
```python
# In config.py
ModelConfig(
    embed_dim=64,
    hidden_dim=128,
    num_layers=3,
    noise_steps=20
)
```

### Training Configuration
```python
TrainingConfig(
    epochs=100,
    batch_size=32,
    learning_rate=0.001,
    early_stopping_patience=10
)
```

## ğŸ¯ Features

### Enhanced Training
- **FocalLoss**: Handles class imbalance
- **Label Smoothing**: Improves generalization
- **Early Stopping**: Prevents overfitting
- **Learning Rate Scheduling**: Adaptive learning rates

### Model Architecture
- **GNN Scorer**: Graph Neural Network for AMP prediction
- **Diffusion Model**: Denoising diffusion for sequence generation
- **Enhanced Loss Functions**: Better training stability

### Quality Evaluation
- **Diversity Metrics**: Sequence diversity analysis
- **AMP Potential**: Antimicrobial activity prediction
- **Validity Checks**: Sequence validity verification
- **Comprehensive Reports**: Detailed quality assessment

## ğŸ“ˆ Performance

### GNN Model Improvements
- Validation loss: -25.1% (0.2706 â†’ 0.2026)
- Validation accuracy: +1.9% (92.35% â†’ 94.10%)
- Training efficiency: +7.7% (13 â†’ 12 epochs)

### Dataset Balance
- **Before**: 3224 AMP + 2 non-AMP sequences
- **After**: 3224 AMP + 3050 non-AMP sequences
- **Improvement**: Balanced dataset for realistic evaluation

## ğŸ› ï¸ Development

### Adding New Features
1. Add code to `src/` modules
2. Create tests in `test/` directory
3. Update documentation in `docs/`
4. Add visualizations if needed

### Code Style
- Follow PEP 8 guidelines
- Use type hints
- Add docstrings for all functions
- Include comprehensive tests

## ğŸ“š Documentation

- [Project Summary](docs/PROJECT_SUMMARY.md)
- [Development Roadmap](docs/roadmap.md)
- [Training Visualization Summary](visualization/training_visualization_summary.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- APD2024 dataset for AMP sequences
- PyTorch for deep learning framework
- Biopython for sequence processing
- Matplotlib/Seaborn for visualizations

---

**Project Status**: âœ… Active Development  
**Last Updated**: 2024-08-24  
**Version**: 0.1.0
